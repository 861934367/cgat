################################################################################
#
#   MRC FGU Computational Genomics Group
#
#   $Id: pipeline_proj007.py 2900 2011-05-24 14:38:00Z david $
#
#   Copyright (C) 2012 David Sims
#
#   This program is free software; you can redistribute it and/or
#   modify it under the terms of the GNU General Public License
#   as published by the Free Software Foundation; either version 2
#   of the License, or (at your option) any later version.
#
#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.
#
#   You should have received a copy of the GNU General Public License
#   along with this program; if not, write to the Free Software
#   Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#################################################################################
"""
===================
Project007 pipeline
===================

:Author: David Sims 
:Release: $Id: pipeline_proj007.py 2900 2011-05-24 14:38:00Z david $
:Date: |today|
:Tags: Python

The project007 pipeline annotates intervals generated by the CAPseq pipeline

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline_capseq.ini` file. The pipeline looks for a configuration file in several places:

   1. The default configuration in the :term:`code directory`.
   2. A shared configuration file :file:`../pipeline.ini`.
   3. A local configuration :file:`pipeline.ini`.

The order is as above. Thus, a local configuration setting will
override a shared configuration setting and a default configuration
setting.

Configuration files follow the ini format (see the python
`ConfigParser <http://docs.python.org/library/configparser.html>` documentation).
The configuration file is organized by section and the variables are documented within 
the file. In order to get a local configuration file in the current directory, type::

    python <codedir>/pipeline_cpg.py config

The sphinxreport report requires a :file:`conf.py` and :file:`sphinxreport.ini` file 
(see :ref:`PipelineDocumenation`). To start with, use the files supplied with the
:ref:`Example` data.


Input
-----

Reads
++++++

Input are :file:`.fastq.gz`-formatted files. The files should be
labeled in the following way::

   sample-condition-replicate.fastq.gz

Note that neither ``sample``, ``condition`` or ``replicate`` should contain 
``_`` (underscore) and ``.`` (dot) characters as these are used by the pipeline
to delineate tasks.

Requirements
------------

The pipeline requires the information from the following pipelines:

:doc:`pipeline_annotations`

set the configuration variables:
   :py:data:`annotations_database` 
   :py:data:`annotations_dir`

On top of the default CGAT setup, the pipeline requires the following software to be in the 
path:

+--------------------+-------------------+------------------------------------------------+
|*Program*           |*Version*          |*Purpose*                                       |
+--------------------+-------------------+------------------------------------------------+
|BEDTools            |                   |interval comparison                             |
+--------------------+-------------------+------------------------------------------------+


Pipline Output
==============

The results of the computation are all stored in an sqlite relational
database :file:`csvdb`.


Code
====

"""
import sys, tempfile, optparse, shutil, itertools, csv, math, random, re, glob, os, shutil, collections, gzip
import sqlite3
import pysam
import IndexedFasta, IndexedGenome, FastaIterator, Genomics
import IOTools
import MAST, GTF, GFF, Bed
import cStringIO
import numpy
import Masker
import fileinput
import gff2annotator
import Experiment as E
import logging as L
import PipelineChipseq as PIntervals
import PipelineTracks
import PipelineMapping
import PipelineGO
from ruffus import *
from rpy2.robjects import r as R
import rpy2.robjects as ro

USECLUSTER = True

###################################################
###################################################
###################################################
## Pipeline configuration
###################################################
import Pipeline as P
P.getParameters(  ["pipeline_proj007.ini", ] )
PARAMS = P.PARAMS
PARAMS_ANNOTATIONS = [0,] #P.peekParameters( PARAMS["geneset_dir"],"pipeline_annotations.py" )

###################################################################
###################################################################
###################################################################
## Helper functions mapping tracks to conditions, etc
###################################################################
# load all tracks - exclude input/control tracks
Sample = PipelineTracks.Sample3

TRACKS = PipelineTracks.Tracks( Sample ).loadFromDirectory( 
    [ x.replace("../","") for x in glob.glob( "../*.export.txt.gz" ) if PARAMS["tracks_control"] not in x ],
      "(\S+).export.txt.gz" ) +\
      PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
          [ x.replace("../","") for x in glob.glob( "../*.sra" ) if PARAMS["tracks_control"] not in x ], 
          "(\S+).sra" ) +\
          PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
              [x.replace("../","") for x in glob.glob( "../*.fastq.gz" ) if PARAMS["tracks_control"] not in x], 
              "(\S+).fastq.gz" ) +\
              PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
                  [x.replace("../","") for x in glob.glob( "../*.fastq.1.gz" ) if PARAMS["tracks_control"] not in x], 
                  "(\S+).fastq.1.gz" ) +\
                  PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
                      [ x.replace("../","") for x in glob.glob( "../*.csfasta.gz" ) if PARAMS["track_control"] not in x], 
                        "(\S+).csfasta.gz" )
for X in TRACKS:
    print "TRACK=", X, "\n"

TRACKS_CONTROL = PipelineTracks.Tracks( Sample ).loadFromDirectory( 
    [ x.replace("../","") for x in glob.glob( "../*.export.txt.gz" ) if PARAMS["tracks_control"] in x ],
      "(\S+).export.txt.gz" ) +\
      PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
          [ x.replace("../","") for x in glob.glob( "../*.sra" ) if PARAMS["tracks_control"] in x ], 
          "(\S+).sra" ) +\
          PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
              [x.replace("../","") for x in glob.glob( "../*.fastq.gz" ) if PARAMS["tracks_control"] in x], 
              "(\S+).fastq.gz" ) +\
              PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
                  [x.replace("../","") for x in glob.glob( "../*.fastq.1.gz" ) if PARAMS["tracks_control"] in x], 
                  "(\S+).fastq.1.gz" ) +\
                  PipelineTracks.Tracks( PipelineTracks.Sample3 ).loadFromDirectory( 
                      [ x.replace("../","") for x in glob.glob( "../*.csfasta.gz" ) if PARAMS["track_control"] in x], 
                        "(\S+).csfasta.gz" )
for X in TRACKS_CONTROL:
    print "TRACK_CONTROL=", X, "\n"

def getControl( track ):
    '''return appropriate control for a track'''
    n = track.clone()
    n.condition = PARAMS["tracks_control"]
    return n

###################################################################
###################################################################
###################################################################
# aggregate per experiment
EXPERIMENTS = PipelineTracks.Aggregate( TRACKS, labels = ("condition", "tissue") )
# aggregate per condition
CONDITIONS = PipelineTracks.Aggregate( TRACKS, labels = ("condition",) )
# aggregate per tissue
TISSUES = PipelineTracks.Aggregate( TRACKS, labels = ("tissue",) )
# compound targets : all experiments
TRACKS_MASTER = EXPERIMENTS.keys() + CONDITIONS.keys()
# compound targets : correlation between tracks
TRACKS_CORRELATION = TRACKS_MASTER + list(TRACKS)

print "Expts=", EXPERIMENTS, "\n"

########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section1: Annotate CAPseq intervals using gene/transcript set
########################################################################################################################
########################################################################################################################
########################################################################################################################

############################################################    
############################################################
## Section 1a: measure overlap with gene/transcript TSS, protein-coding genes, non-coding genes, flanks and intergenic regions
@transform( "../replicated_intervals/*.replicated.bed", regex(r"../replicated_intervals/(\S+).replicated.bed"), r"\1.replicated.bed" )
def copyCapseqReplicatedBedFiles( infile, outfile ):
    '''Copy replicated Bed files generated by capseq pipline to geneset-specific output directory'''
    statement = '''cp %(infile)s .'''
    P.run()

############################################################    
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".geneset_overlap" )
def annotateCapseqGenesetOverlap( infile, outfile ):
    '''classify intervals according to their base pair overlap with respect to different genomic features (genes, TSS, upstream/downstream flanks) '''
    to_cluster = True
    feature_list = P.asList( PARAMS["geneset_feature_list"] )
    outfiles = ""
    first = True
    for feature in feature_list:
        feature_name = P.snip( os.path.basename( feature ), ".gtf" ).replace(".","_")
        outfiles += " %(outfile)s.%(feature_name)s " % locals()
        if first:
            cut_command = "cut -f1,4,5,6,8 "
            first = False
        else:
            cut_command = "cut -f4,5,6 "
        statement = """
                cat %(infile)s
                | python %(scriptsdir)s/bed2gff.py --as-gtf
                | python %(scriptsdir)s/gtf2table.py
		                --counter=overlap
		                --counter=length
		                --log=%(outfile)s.log
		                --filename-gff=%(geneset_dir)s/%(feature)s
		                --genome-file=%(genome_dir)s/%(genome)s
                | %(cut_command)s
                | sed s/nover/%(feature_name)s_nover/g
                | sed s/pover/%(feature_name)s_pover/g
                | sed s/min/length/
                > %(outfile)s.%(feature_name)s"""
        P.run()
    # Paste output together
    statement = '''paste  %(outfiles)s > %(outfile)s'''
    P.run()

############################################################
@transform( annotateCapseqGenesetOverlap, suffix(".geneset_overlap"), ".geneset_overlap.load" )
def loadCapseqGenesetOverlap( infile, outfile ):
    '''load interval annotations: genome architecture '''
    geneset_name = PARAMS["geneset_name"]
    track= P.snip( os.path.basename(infile), ".geneset_overlap").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=%(track)s_%(geneset_name)s_overlap
                         --index=gene_id
                 > %(outfile)s; """
    P.run()
        
############################################################
############################################################
## Section 1b: Count overlap of CAPseq intervals with gene/transcript TSSs
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".transcript_tss.overlap.count" )
def getCapseqTranscriptTSSOverlapCount( infile, outfile ):
    '''Establish overlap between capseq and gene tss intervals'''
    tss = os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_transcript_tss"] )
    to_cluster = True
    statement = """echo "CAPseq intervals overlapping 1 or more TSS" > %(outfile)s; intersectBed -a %(infile)s -b %(tss)s -u | wc -l >> %(outfile)s;  
                   echo "CAPseq intervals not overlapping any TSS" >> %(outfile)s; intersectBed -a %(infile)s -b %(tss)s -v | wc -l >> %(outfile)s; 
                   echo "TSSs overlapped by 1 or more CAPseq interval" >> %(outfile)s; intersectBed -a %(tss)s -b %(infile)s -u | wc -l >> %(outfile)s; 
                   echo "TSSs not overlapped by any CAPseq intervals" >> %(outfile)s; intersectBed -a %(tss)s -b %(infile)s -v | wc -l >> %(outfile)s; 
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; """
    P.run()

############################################################
@transform( getCapseqTranscriptTSSOverlapCount, suffix(".transcript_tss.overlap.count"), ".transcript_tss.overlap.count.load")
def loadCapseqTranscriptTSSOverlapCount(infile, outfile):
    '''Load transcript TSS Capseq overlap into database'''
    header = "track,intervals"
    track = P.snip( os.path.basename( infile), ".transcript_tss.overlap.count" )
    geneset_name = PARAMS["geneset_name"]
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                        --database=%(database)s
                        --table=%(track)s_%(geneset_name)s_transcript_tss_venn
                        --header=%(header)s
                   > %(outfile)s '''
    P.run()
    
############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".gene_tss.overlap.count" )
def getCapseqGeneTSSOverlapCount( infile, outfile ):
    '''Establish overlap between capseq and gene tss intervals'''
    tss = os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_gene_tss"] )
    to_cluster = True
    statement = """echo "CAPseq intervals overlapping 1 or more TSS" > %(outfile)s; intersectBed -a %(infile)s -b %(tss)s -u | wc -l >> %(outfile)s;  
                   echo "CAPseq intervals not overlapping any TSS" >> %(outfile)s; intersectBed -a %(infile)s -b %(tss)s -v | wc -l >> %(outfile)s; 
                   echo "TSSs overlapped by 1 or more CAPseq interval" >> %(outfile)s; intersectBed -a %(tss)s -b %(infile)s -u | wc -l >> %(outfile)s; 
                   echo "TSSs not overlapped by any CAPseq intervals" >> %(outfile)s; intersectBed -a %(tss)s -b %(infile)s -v | wc -l >> %(outfile)s; 
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; """
    P.run()

############################################################
@transform( getCapseqGeneTSSOverlapCount, suffix(".gene_tss.overlap.count"), ".gene_tss.overlap.count.load")
def loadCapseqGeneTSSOverlapCount(infile, outfile):
    '''Load gene TSS Capseq overlap into database'''
    header = "track,intervals"
    track = P.snip( os.path.basename( infile), ".gene_tss.overlap.count" )
    geneset_name = PARAMS["geneset_name"]
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                        --database=%(database)s
                        --table=%(track)s_%(geneset_name)s_gene_tss_venn
                        --header=%(header)s
                   > %(outfile)s '''
    P.run()
    
############################################################
############################################################
## Section 1c: Annotate CAPseq interval TTS/TTS distance
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".transcript.tss.distance" )
def annotateCapseqTranscriptTSSDistance( infile, outfile ):
    '''Compute distance from CAPseq intervals to nearest transcript TSS'''
    to_cluster = True
    annotation_file = os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_transcript_tss"] )
    statement = """cat < %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
	                 | python %(scriptsdir)s/gtf2table.py 
		                   --counter=distance-tss 
		                   --log=%(outfile)s.log 
                       --filename-gff=%(annotation_file)s 
                       --filename-format="bed" 
                   > %(outfile)s"""
    P.run()

############################################################
@transform( annotateCapseqTranscriptTSSDistance, suffix( ".transcript.tss.distance"), ".transcript.tss.distance.load" )
def loadCapseqTranscriptTSSDistance( infile, outfile ):
    '''Load CAPseq interval annotations: distance to transcript transcription start sites '''
    track= P.snip( os.path.basename(infile), ".transcript.tss.distance").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=%(track)s_%(geneset_name)s_transcript_tss_distance
                         --index=gene_id
                         --index=closest_id
                         --index=id5
                         --index=id3
                 > %(outfile)s; """
    P.run()
    
############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".gene.tss.distance" )
def annotateCapseqGeneTSSDistance( infile, outfile ):
    '''Compute distance from CAPseq intervals to nearest gene TSS (single TSS per gene)'''
    to_cluster = True
    annotation_file = os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_gene_tss"] )
    statement = """cat < %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
	                 | python %(scriptsdir)s/gtf2table.py 
		                   --counter=distance-tss 
		                   --log=%(outfile)s.log 
                       --filename-gff=%(annotation_file)s 
                       --filename-format="bed" 
                   > %(outfile)s"""
    P.run()

############################################################
@transform( annotateCapseqGeneTSSDistance, suffix( ".gene.tss.distance"), ".gene.tss.distance.load" )
def loadCapseqGeneTSSDistance( infile, outfile ):
    '''load CAPseq interval annotations: distance to gene transcription start sites '''
    track= P.snip( os.path.basename(infile), ".gene.tss.distance").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=%(track)s_%(geneset_name)s_gene_tss_distance
                         --index=gene_id
                         --index=closest_id
                         --index=id5
                         --index=id3
                 > %(outfile)s; """
    P.run()

############################################################
## Export bed files for CAPseq intervals overlapping TSS intervals
@transform( loadCapseqTranscriptTSSDistance, suffix( ".transcript.tss.distance.load"), ".transcript.tss.bed" )
def exportCapseqTSSBed( infile, outfile ):
    '''export bed file of all CAPseq intervals within 1kb of annotated  transcript TSS '''
    track= P.snip( os.path.basename(infile), ".transcript.tss.distance.load").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    statement = '''SELECT i.contig, i.start, i.end, i.interval_id 
                   FROM %(track)s_intervals i, %(track)s_%(geneset_name)s_transcript_tss_distance t
                   WHERE i.interval_id=t.gene_id 
                   AND t.closest_dist < 1000
                   ORDER by contig, start''' % locals()
    cc.execute( statement )
    outs = open( outfile, "w")
    for result in cc:
        contig, start, stop, interval_id = result
        outs.write( "%s\t%i\t%i\t%i\n" % (contig, start, stop, interval_id) )
    cc.close()
    outs.close()
    
############################################################
@transform( loadCapseqTranscriptTSSDistance, suffix( ".transcript.tss.distance.load"), ".intergenic.bed" )
def exportCapseqIntergenicBed( infile, outfile ):
    '''export bed file of all CAPseq intervals not within 1kb of annotated  transcript TSS '''
    track= P.snip( os.path.basename(infile), ".transcript.tss.distance.load").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    statement = '''SELECT i.contig, i.start, i.end, i.interval_id 
                   FROM %(track)s_intervals i, %(track)s_%(geneset_name)s_transcript_tss_distance t
                   WHERE i.interval_id=t.gene_id 
                   AND t.closest_dist >= 1000
                   ORDER by contig, start''' % locals()
    cc.execute( statement )
    outs = open( outfile, "w")
    for result in cc:
        contig, start, stop, interval_id = result
        outs.write( "%s\t%i\t%i\t%i\n" % (contig, start, stop, interval_id) )
    cc.close()
    outs.close()

############################################################
@transform(copyCapseqReplicatedBedFiles, suffix(".bed"), ".noncoding.tss.distance" )
def getCapseqNoncodingTSSDistance( infile, outfile ):
    '''Calculate distance of CAPseq peaks to nearest non-coding transcript TSS'''
    to_cluster = True
    annotation_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_noncoding_tss"] )
    statement = """cat < %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
	               | python %(scriptsdir)s/gtf2table.py 
		                   --counter=distance-tss 
		                   --log=%(outfile)s.log 
                       --filename-gff=%(annotation_file)s 
                       --filename-format="bed" 
                   > %(outfile)s"""
    P.run()

############################################################
@transform( getCapseqNoncodingTSSDistance, suffix( ".noncoding.tss.distance"), ".noncoding.tss.distance.load" )
def loadCapseqNoncodingTSSDistance( infile, outfile ):
    '''Load interval annotations: distance to non-coding transcription start sites '''
    track= P.snip( os.path.basename(infile), ".noncoding.tss.distance").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=%(track)s_%(geneset_name)s_noncoding_tss_distance
                         --index=gene_id
                         --index=closest_id
                         --index=id5
                         --index=id3
                 > %(outfile)s; """
    P.run()

############################################################
@files( PARAMS["geneset_lncrna_tss"], "lncrna.load" )
def loadlncRNAs( infile, outfile ):
    '''Load external lncRNA dataset into db '''
    header="contig,start,end,id,strand"
    statement = """zcat %(infile)s 
                   | awk 'OFS="\\t" {print $1,$2,$3,$4,$6}'
                   | python ~/src/csv2db.py 
                         --database=%(database)s
                         --header=%(header)s
                         --table=lncrna_bed
                         --index=contig,start
                 > %(outfile)s; """
    P.run()
    
############################################################
@transform(copyCapseqReplicatedBedFiles, suffix(".bed"), ".lncrna.tss.distance" )
def getCapseqlncRNATSSDistance( infile, outfile ):
    '''Calculate distance of CAPseq peaks to nearest lncRNA transcript TSS'''
    to_cluster = True
    annotation_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_lncrna_tss"] )
    statement = """cat < %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
		               --counter=distance-tss 
		               --log=%(outfile)s.log 
                       --filename-gff=%(annotation_file)s 
                       --filename-format="bed" 
                   > %(outfile)s"""
    P.run()

############################################################
@transform( getCapseqlncRNATSSDistance, suffix( ".lncrna.tss.distance"), ".lncrna.tss.distance.load" )
def loadCapseqlncRNATSSDistance( infile, outfile ):
    '''Load interval annotations: distance to lncRNA transcription start sites '''
    track= P.snip( os.path.basename(infile), ".lncrna.tss.distance").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=%(track)s_lncrna_tss_distance
                         --index=gene_id
                         --index=closest_id
                         --index=id5
                         --index=id3
                 > %(outfile)s; """
    P.run()
        
############################################################
############################################################
## Section 1d: Calculate pileup of CAPseq reads over TSS/TTS
@follows( mkdir("tss-profile") )
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.transcript.tss-profile.all.png" )
def getReplicatedTranscriptTSSProfile(infile, outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    tss_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    ofp = "tss-profile/" + track + ".replicated.transcript.tss-profile.all"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tss_file)s
                       --output-filename-pattern=%(ofp)s
                       --reporter=transcript
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
## TSSs associated (within 1kb) with a CAPseq interval only
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.transcript.tss-profile.capseq.png" )
def getReplicatedTranscriptTSSProfileCapseq(infile,outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    ofp = "tss-profile/" + track + ".replicated.transcript.tss-profile.capseq"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    gene_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    tss_file = os.path.join( PARAMS["geneset_dir"],  PARAMS["geneset_transcript_tss"])
    tmpfile = P.getTempFile()
    tmpfilename = tmpfile.name
    statement = '''intersectBed -a %(tss_file)s -b %(infile)s -u | cut -f4 > %(tmpfilename)s; 
                   zcat %(gene_file)s | python %(scriptsdir)s/gtf2gtf.py --filter=transcript --apply=%(tmpfilename)s | gzip > %(tmpfilename)s.gtf.gz; 
                   python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tmpfilename)s.gtf.gz
                       --output-filename-pattern=%(ofp)s
                       --reporter=transcript
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
## TSSs NOT associated (within 1kb) with a CAPseq interval only
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.transcript.tss-profile.nocapseq.png" )
def getReplicatedTranscriptTSSProfileNoCapseq(infile,outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    ofp = "tss-profile/" + track + ".replicated.transcript.tss-profile.nocapseq"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    gene_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    tss_file = os.path.join( PARAMS["geneset_dir"],  PARAMS["geneset_transcript_tss"])
    tmpfile = P.getTempFile()
    tmpfilename = tmpfile.name
    statement = '''intersectBed -a %(tss_file)s -b %(infile)s -v | cut -f4 > %(tmpfilename)s; 
                   zcat %(gene_file)s | python %(scriptsdir)s/gtf2gtf.py --filter=transcript --apply=%(tmpfilename)s | gzip > %(tmpfilename)s.gtf.gz; 
                   python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tmpfilename)s.gtf.gz
                       --output-filename-pattern=%(ofp)s
                       --reporter=transcript
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
## Per gene
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.gene.tss-profile.all.png" )
def getReplicatedGeneTSSProfile(infile, outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    tss_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    ofp = "tss-profile/" + track + ".replicated.gene.tss-profile.all"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tss_file)s
                       --output-filename-pattern=%(ofp)s
                       --reporter=gene
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.gene.tss-profile.capseq.png" )
def getReplicatedGeneTSSProfileCapseq(infile,outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    ofp = "tss-profile/" + track + ".replicated.gene.tss-profile.capseq"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    gene_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    tss_file = os.path.join( PARAMS["geneset_dir"],  PARAMS["geneset_transcript_tss"])
    tmpfile = P.getTempFile()
    tmpfilename = tmpfile.name
    statement = '''intersectBed -a %(tss_file)s -b %(infile)s -u | cut -f4 > %(tmpfilename)s; 
                   zcat %(gene_file)s | python %(scriptsdir)s/gtf2gtf.py --filter=transcript --apply=%(tmpfilename)s | gzip > %(tmpfilename)s.gtf.gz; 
                   python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tmpfilename)s.gtf.gz
                       --output-filename-pattern=%(ofp)s
                       --reporter=gene
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"tss-profile/\1.replicated.gene.tss-profile.nocapseq.png" )
def getReplicatedGeneTSSProfileNoCapseq(infile,outfile):
    '''Build TSS profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    ofp = "tss-profile/" + track + ".replicated.gene.tss-profile.nocapseq"
    # setup files
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    gene_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    tss_file = os.path.join( PARAMS["geneset_dir"],  PARAMS["geneset_transcript_tss"])
    tmpfile = P.getTempFile()
    tmpfilename = tmpfile.name
    statement = '''intersectBed -a %(tss_file)s -b %(infile)s -v | cut -f4 > %(tmpfilename)s; 
                   zcat %(gene_file)s | python %(scriptsdir)s/gtf2gtf.py --filter=transcript --apply=%(tmpfilename)s | gzip > %(tmpfilename)s.gtf.gz; 
                   python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tmpfilename)s.gtf.gz
                       --output-filename-pattern=%(ofp)s
                       --reporter=gene
                       --method=tssprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################
############################################################
## Section 1d: Calculate pileup of CAPseq reads over genes
@follows( mkdir("gene-profile") )
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"gene-profile/\1.replicated.transcript-profile.all.png" )
def getReplicatedTranscriptProfile(infile, outfile):
    '''Build transcript profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    tss_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    ofp = "gene-profile/" + track + ".replicated.transcript-profile.all"
    # setup files
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       %(shifts)s 
                       --gtffile=%(tss_file)s
                       --output-filename-pattern=%(ofp)s
                       --reporter=transcript
                       --method=geneprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()

############################################################   
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"gene-profile/\1.replicated.gene-profile.all.png" ) 
def getReplicatedGeneProfile(infile, outfile):
    '''Build transcript profile from BAM files'''
    to_cluster = USECLUSTER
    track = P.snip( os.path.basename(infile), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    tss_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    ofp = "gene-profile/" + track + ".replicated.gene-profile.all"
    # setup files
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )
    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                       %(bamfiles)s 
                       --gtffile=%(tss_file)s
                       --output-filename-pattern=%(ofp)s
                       %(shifts)s
                       --reporter=gene
                       --method=geneprofile
                       --normalization=total-sum
                       --normalize-profile=area
                       --normalize-profile=counts
                       --normalize-profile=none'''
    P.run()
    
############################################################
############################################################
## Section 1f: Export lists of genes with TSS-associated CAPseq intervals
@transform( loadCapseqTranscriptTSSDistance, suffix(".transcript.tss.distance.load"), ".tss_1kb.genelist")
def exportCapseqTSSDistanceGeneList( infile, outfile):
    '''Export list of genes where one or more transcript TSS is within 1kb of a replicated CAPseq interval'''
    max_gene_dist = 1000
    geneset_name = PARAMS["geneset_name"]
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".transcript.tss.distance.load" ).replace("-","_").replace(".","_")
    # Extract data from db
    cc = dbhandle.cursor()
    query = '''SELECT closest_id FROM %(track)s_%(geneset_name)s_transcript_tss_distance 
               WHERE closest_dist < %(max_gene_dist)s ORDER BY closest_dist;''' % locals()
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        ids = str(result[0])
        genes = ids.split(",")
        for g in genes:
            outs.write( "%s\n" % g )
    cc.close()
    outs.close()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".transcript.tss.genelist")
def exportCapseqTranscriptTSSOverlapGeneList( infile, outfile):
    '''Export list of genes where one or more extended transcript TSS overlaps a replicated CAPseq interval'''
    # Currently outputs transcript list
    transcript_tss_bed = PARAMS["geneset_transcript_tss"]
    geneset_dir = PARAMS["geneset_dir"]
    statement = '''intersectBed -a %(geneset_dir)s/%(transcript_tss_bed)s -b %(infile)s -u | cut -f4 > %(outfile)s'''
    P.run()

############################################################
############################################################
## Compare CAPseq intervals with genomic features using GAT
@follows( mkdir("gat") )
@files(PARAMS["samtools_genome"]+".fai", "gat/"+PARAMS["genome"]+".bed.gz")
def buildGATWorkspace(infile, outfile ):
    '''Build genomic workspace file for GAT '''
    statement = '''cat %(infile)s | awk 'OFS="\\t" {print $1,0,$2,"workspace"}' | gzip > %(outfile)s '''
    P.run()
    
############################################################
@follows(buildGATWorkspace)
@merge( copyCapseqReplicatedBedFiles, "gat/genomic_features_gat.tsv" )
def runGenomicFeaturesGAT(infiles, outfile):
    '''Run genome association tester on bed files '''
    to_cluster = True
    
    # Segment files
    segfiles = ""
    for x in infiles:
        track = P.snip(os.path.basename(x), ".replicated.bed")
        statement = """cat %(x)s | awk 'OFS="\\t" {print $1,$2,$3,"%(track)s"}' > gat/%(track)s.bed; """
        P.run()
        segfiles += " --segment-file=gat/%s.bed " % track
        
    # Annotation files
    annofiles = ""
    anno_list = P.asList(PARAMS["geneset_feature_list"])
    anno_dir = PARAMS["geneset_dir"]
    for y in anno_list:
        annotrack = P.snip(os.path.basename(y), ".gtf")
        statement = """cat %(anno_dir)s/%(y)s | python %(scriptsdir)s/gff2bed.py --name='feature' --is-gtf | sed s/exon/%(annotrack)s/g > gat/%(annotrack)s.bed; """
        P.run()
        annofiles += " --annotation-file=gat/%s.bed " % annotrack
    # Run GAT
    statement = """gatrun.py %(segfiles)s %(annofiles)s --workspace=gat/%(genome)s.bed.gz --num-samples=1000 --force --nbuckets=120000 > %(outfile)s"""
    P.run()

############################################################
@transform( runGenomicFeaturesGAT, suffix(".tsv"), ".tsv.load" )
def loadGenomicFeaturesGAT(infile, outfile):
    '''Load genome association tester results into database '''
    statement = """cat %(infile)s | grep -v "^#" | python %(scriptsdir)s/csv2db.py 
                       --database=%(database)s
                       --table=gat_genomic_features_results 
                   > %(outfile)s"""
    P.run()    


########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 2: Annotate CAPseq interval nucleotide composition
########################################################################################################################
########################################################################################################################
########################################################################################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".capseq.composition" )
def annotateCapseqComposition( infile, outfile ):
    '''Establish the nucleotide composition of intervals'''

    to_cluster = True
    statement = """cat %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateCapseqComposition, suffix( ".composition"), ".composition.load" )
def loadCapseqComposition( infile, outfile ):
    '''Load the nucleotide composition of intervals'''

    track= P.snip( os.path.basename(infile), ".composition").replace(".cleaned","").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=%(track)s_composition 
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".control.composition" )
def annotateControlComposition( infile, outfile ):
    '''Establish the nucleotide composition of control intervals'''

    to_cluster = True
    track= P.snip( os.path.basename(infile), ".bed")
    dirname= os.path.dirname(infile)

    statement = """cat %(infile)s | python %(scriptsdir)s/bed2bed.py -m shift -g %(genome_dir)s/%(genome)s --offset=-10000 -S %(track)s.control.bed;
                   cat %(track)s.control.bed
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateControlComposition, suffix( ".control.composition"), ".control.composition.load" )
def loadControlComposition( infile, outfile ):
    '''Load the nucleotide composition of intervals'''
    track= P.snip( os.path.basename(infile), ".control.composition").replace(".cleaned","").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=%(track)s_composition_control
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".flanking5.composition" )
def annotateFlankingCompositionLeft( infile, outfile ):
    '''Establish the nucleotide composition of intervals immediately upstream'''
    to_cluster = True
    track= P.snip( os.path.basename(infile), ".bed")
    dirname= os.path.dirname(infile)
    flank_size = PARAMS["geneset_flank_size"]
    # Exclude intervals with length < 100bp
    statement = """flankBed -i %(infile)s -l %(flank_size)s -r 0 -g %(samtools_genome)s.fai 
                   | python %(scriptsdir)s/bed2bed.py --method=filter-genome --genome-file=%(genome_dir)s/%(genome)s -L %(track)s.flanking5.log 
                   | awk 'OFS="\\t" {if ($3-$2>100) print $1,$2,$3,$4}' > %(track)s.flanking5.bed;
                   cat %(track)s.flanking5.bed
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateFlankingCompositionLeft, suffix( ".flanking5.composition"), ".flanking5.composition.load" )
def loadFlankingCompositionLeft( infile, outfile ):
    '''Load the nucleotide composition of regions flanking intervals'''

    track= P.snip( os.path.basename(infile), ".flanking5.composition").replace(".cleaned","").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=%(track)s_composition_flanking5
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".flanking3.composition" )
def annotateFlankingCompositionRight( infile, outfile ):
    '''Establish the nucleotide composition of intervals immediately downstream'''

    to_cluster = True
    track= P.snip( os.path.basename(infile), ".bed")
    dirname= os.path.dirname(infile)
    flank_size = PARAMS["geneset_flank_size"]

    # Exclude intervals with length < 100bp
    statement = """flankBed -i %(infile)s -l 0 -r 1000 -g %(samtools_genome)s.fai 
                   | python %(scriptsdir)s/bed2bed.py --method=filter-genome --genome-file=%(genome_dir)s/%(genome)s -L %(track)s.flanking3.log 
                   | awk 'OFS="\\t" {if ($3-$2>100) print $1,$2,$3,$4}' > %(track)s.flanking3.bed;
                   cat %(track)s.flanking3.bed
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateFlankingCompositionRight, suffix( ".flanking3.composition"), ".flanking3.composition.load" )
def loadFlankingCompositionRight( infile, outfile ):
    '''Load the nucleotide composition of regions flanking intervals'''
    track= P.snip( os.path.basename(infile), ".flanking3.composition").replace(".cleaned","").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=%(track)s_composition_flanking3
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
############################################################
@transform( loadCapseqComposition, suffix(".replicated.composition.load"), ".replicated.gc.export" )
def exportCapseqGCProfiles( infile, outfile ):
    '''Export file of GC content '''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".replicated.composition.load" ).replace("-","_").replace(".","_")
    # Extract data from db
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pGC, cc.pGC, c3.pGC, c5.pGC 
               FROM %(track)s_replicated_composition c
               left join %(track)s_replicated_composition_control cc on c.gene_id=cc.gene_id
               left join %(track)s_replicated_composition_flanking3 c3 on c.gene_id=c3.gene_id
               left join %(track)s_replicated_composition_flanking5 c5 on c.gene_id=c5.gene_id;''' % locals()
    cc.execute( query )
    E.info( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadCapseqComposition, suffix(".replicated.composition.load"), ".replicated.cpg.export" )
def exportCapseqCpGObsExp( infile, outfile ):
    '''Export file of GC content '''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".replicated.composition.load" ).replace("-","_").replace(".","_")
    # Extract data from db
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.CpG_ObsExp, cc.CpG_ObsExp, c3.CpG_ObsExp, c5.CpG_ObsExp 
               FROM %(track)s_replicated_composition c
               left join %(track)s_replicated_composition_control cc on c.gene_id=cc.gene_id
               left join %(track)s_replicated_composition_flanking3 c3 on c.gene_id=c3.gene_id
               left join %(track)s_replicated_composition_flanking5 c5 on c.gene_id=c5.gene_id;''' % locals()
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
            outs.write("%s%s" % (pre, str(r)) )
            pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadCapseqComposition, suffix(".replicated.composition.load"), ".replicated.cpg_density.export" )
def exportCapseqCpGDensity( infile, outfile ):
    '''Export file of GC content '''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".replicated.composition.load" ).replace("-","_").replace(".","_")
    # Extract data from db
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pCpG, cc.pCpG, c3.pCpG, c5.pCpG 
               FROM %(track)s_replicated_composition c
               left join %(track)s_replicated_composition_control cc on c.gene_id=cc.gene_id
               left join %(track)s_replicated_composition_flanking3 c3 on c.gene_id=c3.gene_id
               left join %(track)s_replicated_composition_flanking5 c5 on c.gene_id=c5.gene_id;''' % locals()
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
            outs.write("%s%s" % (pre, str(r)) )
            pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

          
########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 3: Compare CAPseq intervals with external datasets
########################################################################################################################
########################################################################################################################
########################################################################################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".cgi_overlap")
def getCapseqCGIOverlapCount(infile, outfile):
    '''identify intervals overlapping CGI for each datasets'''
    CGI = P.asList(PARAMS["bed_cgi"])
    if os.path.exists(outfile):
        statement = '''rm %(outfile)s'''
        P.run()
    for dataset in CGI:
       dataset_name =  P.snip( os.path.basename( dataset ), ".bed")
       statement = '''echo %(dataset_name)s >> %(outfile)s; intersectBed -a %(infile)s -b %(dataset)s -u | wc -l >> %(outfile)s; '''
       P.run()
    statement = '''sed -i '{N;s/\\n/\\t/}' %(outfile)s; '''
    P.run()

############################################################
@transform( getCapseqCGIOverlapCount, suffix(".cgi_overlap"), ".cgi_overlap.load")
def loadCapseqCGIOverlapCount(infile, outfile):
    '''Load intervals overlapping CGI into database '''
    track = P.snip( os.path.basename( infile ), ".cgi_overlap" ).replace(".","_").replace("-","_")
    header = "track,overlap"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_cgi_venn
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".cgi_cap.bed")
def getCGIAndCapseqIntervals(infile, outfile):
    '''identify intervals overlapping CGI for each datasets'''
    CGI = PARAMS["bed_ucsc_cgi"]
    dataset_name =  P.snip( os.path.basename( CGI ), ".bed")
    statement = '''intersectBed -a %(infile)s -b %(CGI)s -u > %(outfile)s; '''
    P.run()

############################################################
@transform( getCGIAndCapseqIntervals, suffix(".cgi_cap.bed"), ".cgi_cap.bed.load")
def loadCGIAndCapseqIntervals(infile, outfile):
    '''Load intervals overlapping CGI into database '''
    track = P.snip( os.path.basename( infile ), ".cgi_cap.bed" ).replace(".","_").replace("-","_")
    header = "contig,start,stop,interval_id"
    statement = '''cat %(infile)s | awk 'OFS="\\t" {print $1,$2,$3,$4}' | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_predicted_cgi_and_cap
                      --index=contig,start
                      --index=interval_id
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".cap_only.bed")
def getCapseqSpecificIntervals(infile, outfile):
    '''identify CApseq intervals not overlapping predicted CGI for each dataset'''
    CGI = PARAMS["bed_ucsc_cgi"]
    dataset_name =  P.snip( os.path.basename( CGI ), ".bed")
    statement = '''intersectBed -a %(infile)s -b %(CGI)s -v > %(outfile)s; '''
    P.run()

############################################################
@transform( getCapseqSpecificIntervals, suffix(".cap_only.bed"), ".cap_only.bed.load")
def loadCapseqSpecificIntervals(infile, outfile):
    '''Load intervals not overlapping CGI into database '''
    track = P.snip( os.path.basename( infile ), ".cap_only.bed" ).replace(".","_").replace("-","_")
    header = "contig,start,stop,interval_id"
    statement = '''cat %(infile)s | awk 'OFS="\\t" {print $1,$2,$3,$4}' | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_cap_not_predicted_cgi
                      --index=contig,start
                      --index=interval_id
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()

############################################################
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".cgi_only.bed")
def getPredictedCGIIntervals(infile, outfile):
    '''identify predicted CGI intervals not overlapping CAPseq intervals for each dataset'''
    CGI = PARAMS["bed_ucsc_cgi"]
    statement = '''cat %(CGI)s | awk 'OFS="\\t" {print $1,$2,$3,$4NR}' | intersectBed -a stdin -b %(infile)s -v > %(outfile)s; '''
    P.run()

############################################################
@transform( getPredictedCGIIntervals, suffix(".cgi_only.bed"), ".cgi_only.bed.load")
def loadPredictedCGIIntervals(infile, outfile):
    '''Load predicted CGI intervals not overlapping CAP-seq intervals into database '''
    track = P.snip( os.path.basename( infile ), ".cgi_only.bed" ).replace(".replicated","")
    table = P.snip( os.path.basename( infile ), ".cgi_only.bed" ).replace(".","_").replace("-","_")
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]

    # Write header to output file
    tmpfile = tempfile.NamedTemporaryFile(delete=False)
    headers = ( "contig","start","stop","interval_id","nPeaks","PeakCenter","Length","AvgVal","PeakVal","nProbes" )
    tmpfile.write( "\t".join(headers) + "\n" )
    contig,start,end,interval_id,npeaks,peakcenter,length,avgval,peakval,nprobes = "",0,0,0,0,0,0,0,0,0

    # setup files
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( pysam.Samfile( fn,  "rb" ) )
        fn = "../macs/with_input/%s.macs" % t
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )

    # Loop over input Bed file and calculate stats for merged intervals
    c = E.Counter()
    for line in open(infile, "r"):
        c.input += 1
        contig, start, end, interval_id = line[:-1].split()[:4]
        start, end = int(start), int(end)
        #interval_id = c.input
        npeaks, peakcenter, length, avgval, peakval, nprobes = PIntervals.countPeaks( contig, start, end, samfiles, offsets )
        if nprobes == 0:
            c.skipped_reads += 1
        c.output += 1
        tmpfile.write( "\t".join( map( str, (contig,start,end,interval_id,npeaks,peakcenter,length,avgval,peakval,nprobes) )) + "\n" )
    tmpfile.close()
    tmpfilename = tmpfile.name
    tablename = "%s_predicted_cgi_not_cap" % table
    
    statement = '''python %(scriptsdir)s/csv2db.py %(csv2db_options)s
                       --database=%(database)s
                       --index=contig,start 
                       --table=%(tablename)s
                       --allow-empty
                   < %(tmpfilename)s > %(outfile)s '''
    P.run()
    os.unlink( tmpfile.name )
    L.info( "%s\n" % str(c) )
    
############################################################
## Load external bed file stats
@merge( "external_bed/*.bed", "external_interval_sets.stats" )
def getExternalBedStats(infiles, outfile):
    '''Calculate statistics for external bed files '''
    chromatin = P.asList(PARAMS["bed_chromatin"])
    capseq = P.asList(PARAMS["bed_capseq"])
    chipseq = P.asList(PARAMS["bed_chipseq"])
    CGI = P.asList(PARAMS["bed_cgi"])
    extBed = chromatin + capseq + chipseq + CGI

    if os.path.exists(outfile):
        statement = '''rm %(outfile)s'''
        P.run()

    for f in extBed:
        if len(f) > 0:
            track = P.snip( os.path.basename(f),".bed" )
            statement = """echo '%(track)s' >> %(outfile)s; cat %(f)s | wc -l >> %(outfile)s; """
            P.run()
    statement = '''sed -i '{N;s/\\n/\\t/}' %(outfile)s; '''
    P.run()

############################################################
@transform( getExternalBedStats, suffix(".stats"), ".stats.load" )
def loadExternalBedStats(infile, outfile):
    '''Load statistics for external bed files into database '''
    statement = """cat %(infile)s | python %(scriptsdir)s/csv2db.py
                         --database=%(database)s
                         --header=bed,intervals
                         --table=external_interval_sets 
                    > %(outfile)s"""
    P.run()

############################################################
## Compare CAPseq intervals with chromatin marks
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".chromatin")
def getChromatinMarkOverlap(infile, outfile):
    '''identify intervals overlapping chromatin mark intervals for each datasets'''
    chromatin = P.asList(PARAMS["bed_chromatin"])
    if os.path.exists(outfile):
        statement = '''rm %(outfile)s'''
        P.run()
    if len(chromatin[0]) > 0:
        for mark in chromatin:
           dataset_name =  P.snip( os.path.basename( mark ), ".bed")
           statement = '''echo %(dataset_name)s >> %(outfile)s; intersectBed -a %(infile)s -b %(mark)s -u | wc -l >> %(outfile)s; '''
           P.run()
        statement = '''sed -i '{N;s/\\n/\\t/}' %(outfile)s; '''
        P.run()
    else:
        statement = '''touch %(outfile)s '''
        P.run()

############################################################
@transform( getChromatinMarkOverlap, suffix(".chromatin"), ".chromatin.load")
def loadChromatinMarkIntervals(infile, outfile):
    '''Load intervals overlapping chromatin marks into database '''
    track = P.snip( os.path.basename( infile ), ".chromatin" ).replace(".","_").replace("-","_")
    header = "track,overlap"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                       --database=%(database)s
                      --table=%(track)s_chromatin
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()
        
############################################################
## Compare CAPseq intervals with ChIP-seq intervals
@transform(copyCapseqReplicatedBedFiles, suffix(".bed"), ".chipseq")
def getChipseqOverlap(infile, outfile):
    '''identify intervals overlapping chipseq intervals for each datasets'''
    chipseq = P.asList(PARAMS["bed_chipseq"])
    if os.path.exists(outfile):
        statement = '''rm %(outfile)s'''
        P.run()
    if len(chipseq[0]) > 0:
        for tf in chipseq:
           dataset_name =  P.snip( os.path.basename( tf ), ".bed")
           statement = '''echo %(dataset_name)s >> %(outfile)s; intersectBed -a %(infile)s -b %(tf)s -u | wc -l >> %(outfile)s; '''
           P.run()
        statement = '''sed -i '{N;s/\\n/\\t/}' %(outfile)s; '''
        P.run()
    else:
        statement = '''touch %(outfile)s '''
        P.run()

############################################################
@transform( getChipseqOverlap, suffix(".chipseq"), ".chipseq.load")
def loadChipseqIntervals(infile, outfile):
    '''Load intervals overlapping chipseq into database '''
    track = P.snip( os.path.basename( infile ), ".chipseq" ).replace(".","_").replace("-","_")
    header = "track,overlap"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_chipseq
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()

############################################################
## Compare CAPseq intervals with external CAPseq intervals
@transform( copyCapseqReplicatedBedFiles, suffix(".bed"), ".capseq")
def getCapseqOverlap(infile, outfile):
    '''identify intervals overlapping capseq intervals for each datasets'''
    capseq = P.asList(PARAMS["bed_capseq"])
    if os.path.exists(outfile):
        statement = '''rm %(outfile)s'''
        P.run()
    if len(capseq[0]) > 0:
        for x in capseq:
            dataset_name =  P.snip( os.path.basename( x ), ".bed")
            statement = '''echo %(dataset_name)s >> %(outfile)s; intersectBed -a %(infile)s -b %(x)s -u | wc -l >> %(outfile)s; '''
            P.run()
        statement = '''sed -i '{N;s/\\n/\\t/}' %(outfile)s; '''
        P.run()
    else:
        statement = '''touch %(outfile)s '''
        P.run()

############################################################
@transform( getCapseqOverlap, suffix(".capseq"), ".capseq.load")
def loadCapseqIntervals(infile, outfile):
    '''Load intervals overlapping capseq into database '''
    track = P.snip( os.path.basename( infile ), ".capseq" ).replace(".","_").replace("-","_")
    header = "track,overlap"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_capseq
                      --header=%(header)s
                      --allow-empty
                   > %(outfile)s '''
    P.run()

############################################################
############################################################
## Compare intervals to external bed files using GAT
@follows( buildGATWorkspace )
@merge( copyCapseqReplicatedBedFiles, "gat/external_dataset_gat.tsv" )
def runExternalDatasetGAT(infiles, outfile):
    '''Run genome association tester on bed files '''
    to_cluster = True
    segfiles = ""
    for x in infiles:
        track = P.snip(os.path.basename(x), ".bed")
        statement = """cat %(x)s | awk 'OFS="\\t" {print $1,$2,$3,"%(track)s"}' > gat/%(track)s.bed; """
        P.run()
        segfiles += " --segment-file=gat/%s.bed " % track 

    # External datasets
    chromatin = P.asList(PARAMS["bed_chromatin"])
    capseq = P.asList(PARAMS["bed_capseq"])
    chipseq = P.asList(PARAMS["bed_chipseq"])
    CGI = P.asList(PARAMS["bed_cgi"])
    extBed = chromatin + capseq + chipseq + CGI
    annofiles = " ".join( [ "--annotation-file=%s" % x for x in extBed ] )
    statement = """gatrun.py %(segfiles)s %(annofiles)s --workspace=gat/%(genome)s.bed.gz --num-samples=1000 --nbuckets=120000 --force > %(outfile)s"""
    P.run()

############################################################
@transform( runExternalDatasetGAT, suffix(".tsv"), ".tsv.load" )
def loadExternalDatasetGAT(infile, outfile):
    '''Load genome association tester results into database '''
    statement = """cat %(infile)s | grep -v "^#" | python %(scriptsdir)s/csv2db.py
                         --database=%(database)s
                         --table=external_dataset_gat_results gat/external_dataset_gat.tsv
                    > %(outfile)s"""
    P.run()

########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 4: Annotate predicted CGI Intervals
########################################################################################################################
########################################################################################################################
########################################################################################################################
@follows( mkdir("cgi") )
@files( PARAMS["bed_ucsc_cgi"], "cgi/ucsc.bed.load")
def loadUCSCPredictedCGIIntervals(infile, outfile):
    '''load CGI intervals'''
    header = "contig,start,stop,id"
    statement = '''cat %(infile)s | awk 'OFS="\\t" {print $1,$2,$3,$4NR}' | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=cgi_intervals
                      --index=contig,start
                      --index=id
                      --header=%(header)s
                   > %(outfile)s '''
    P.run()
    
############################################################
############################################################
## CGI nucleotide composition
@follows( loadUCSCPredictedCGIIntervals )
@files( PARAMS["bed_ucsc_cgi"], "cgi/cgi.composition" )
def annotateCGIComposition( infile, outfile ):
    '''Establish the nucleotide composition of CGI intervals'''
    to_cluster = True

    # Give each row a unique identifier
    statement = """cat %(infile)s 
                   | awk '{print $1,$2,$3,$4NR}'
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                         --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateCGIComposition, suffix( ".composition"), ".composition.load" )
def loadCGIComposition( infile, outfile ):
    '''Load the nucleotide composition of CGI intervals'''

    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=cgi_comp
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@transform( loadCGIComposition, suffix("cgi.composition.load"), "cgi.gc.export" )
def exportCGIGCProfiles( infile, outfile ):
    '''Export file of GC content '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pGC FROM cgi_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadCGIComposition, suffix("cgi.composition.load"), "cgi.cpg_density.export" )
def exportCGICpGDensity( infile, outfile ):
    '''Export file of CpG density '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pCpG FROM cgi_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadCGIComposition, suffix("cgi.composition.load"), "cgi.cpg.export" )
def exportCGICpGObsExp( infile, outfile ):
    '''Export file of CpG Observed / expected ratio '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.CpG_ObsExp FROM cgi_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()
        
############################################################    
############################################################
## Compare predicted CGI intervals from UCSC with  TSS annotations
@files( ( os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_transcript_tss"] ), PARAMS["bed_ucsc_cgi"]), "cgi/cgi.transcript_tss.overlap.count" )
def getCGITranscriptTSSOverlapCount( infiles, outfile ):
    '''Establish overlap between UCSC predicted CGIs and  protein-coding transcript TSS intervals'''
    tss, cgi = infiles
    to_cluster = True
    statement = '''echo "Predicted CGIs overlapping 1 or more TSS" > %(outfile)s; intersectBed -a %(cgi)s -b %(tss)s -u | wc -l >> %(outfile)s; 
                   echo "Predicted CGIs not overlapping any TSS" >> %(outfile)s; intersectBed -a %(cgi)s -b %(tss)s -v | wc -l >> %(outfile)s; 
                   echo "TSS overlapped by 1 or more CGI" >> %(outfile)s; intersectBed -a %(tss)s -b %(cgi)s -u | wc -l >> %(outfile)s; 
                   echo "TSS not overlapped by any predicted CGI" >> %(outfile)s; intersectBed -a %(tss)s -b %(cgi)s -v | wc -l >> %(outfile)s; 
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; '''
    P.run()

############################################################    
@transform( getCGITranscriptTSSOverlapCount, regex(r"cgi/cgi.transcript_tss.overlap.count"), r"cgi/cgi.transcript_tss.overlap.count.load")
def loadCGITranscriptTSSOverlapCount(infile, outfile):
    '''Load UCSC predicted CGI overlap with  protein-coding transcript TSSs into database'''
    header = "track,intervals"
    geneset_name = PARAMS["geneset_name"]
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                        --database=%(database)s
                        --table=cgi_%(geneset_name)s_transcript_tss_venn
                        --header=%(header)s
                   > %(outfile)s '''
    P.run()    

############################################################
@files( ( os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_gene_tss"] ), PARAMS["bed_ucsc_cgi"]), "cgi/cgi.gene_tss.overlap.count" )
def getCGIGeneTSSOverlapCount( infiles, outfile ):
    '''Establish overlap between UCSC predicted CGIs and  protein-coding gene TSS intervals'''
    tss, cgi = infiles
    to_cluster = True
    statement = """echo "Predicted CGIs overlapping 1 or more TSS" > %(outfile)s; intersectBed -a %(cgi)s -b %(tss)s -u | wc -l >> %(outfile)s; 
                   echo "Predicted CGIs not overlapping any TSS" >> %(outfile)s; intersectBed -a %(cgi)s -b %(tss)s -v | wc -l >> %(outfile)s; 
                   echo "TSS overlapped by 1 or more CGI" >> %(outfile)s; intersectBed -a %(tss)s -b %(cgi)s -u | wc -l >> %(outfile)s; 
                   echo "TSS not overlapped by any predicted CGI" >> %(outfile)s; intersectBed -a %(tss)s -b %(cgi)s -v | wc -l >> %(outfile)s; 
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; """
    P.run()

############################################################
@transform( getCGIGeneTSSOverlapCount, regex(r"cgi/cgi.gene_tss.overlap.count"), r"cgi/cgi.gene_tss.overlap.count.load")
def loadCGIGeneTSSOverlapCount(infile, outfile):
    '''Load UCSC predicted CGI overlap with  protein-coding gene TSSs into database'''
    header = "track,intervals"
    geneset_name = PARAMS["geneset_name"]
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                        --database=%(database)s
                        --table=cgi_%(geneset_name)s_gene_tss_venn
                        --header=%(header)s
                   > %(outfile)s '''
    P.run()

############################################################
############################################################
## Record overlap of intervals with  protein-coding gene/transcript models
@files( PARAMS["bed_ucsc_cgi"], "cgi/cgi.geneset.overlap" )
def annotateCGIGenesetOverlap( infile, outfile ):
    '''classify predicted CGI intervals according to their base pair overlap 
       with respect to different genomic features (genes, TSS, upstream/downstream flanks) '''
    to_cluster = True
    feature_list = P.asList( PARAMS["geneset_feature_list"] )
    outfiles = ""
    first = True
    for feature in feature_list:
        feature_name = P.snip( os.path.basename( feature ), ".gtf" ).replace(".","_")
        outfiles += " %(outfile)s.%(feature_name)s " % locals()
        if first:
            cut_command = "cut -f1,4,5,6,8 "
            first = False
        else:
            cut_command = "cut -f4,5,6 "
        statement = """
                cat %(infile)s 
                | awk '{print $1,$2,$3,$4NR}'
                | python %(scriptsdir)s/bed2gff.py --as-gtf 
                | python %(scriptsdir)s/gtf2table.py 
		                --counter=overlap  
		                --counter=length  
		                --log=%(outfile)s.log 
		                --filename-gff=%(geneset_dir)s/%(feature)s 
		                --genome-file=%(genome_dir)s/%(genome)s
                | %(cut_command)s 
                | sed s/nover/%(feature_name)s_nover/g 
                | sed s/pover/%(feature_name)s_pover/g 
                | sed s/min/length/
                > %(outfile)s.%(feature_name)s"""
        P.run()
    # Paste output together
    statement = '''paste  %(outfiles)s > %(outfile)s'''
    P.run()

############################################################
@transform( annotateCGIGenesetOverlap, suffix(".geneset.overlap"), ".geneset.overlap.load" )
def loadCGIGenesetOverlap( infile, outfile ):
    '''load interval annotations: genome architecture '''
    track= P.snip( os.path.basename(infile), ".geneset.overlap").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=%(track)s_%(geneset_name)s_overlap 
                         --index=gene_id
                 > %(outfile)s; """
    P.run()
          
########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 5: Annotate nucleotide composition of protein-coding / non-coding TSSs
########################################################################################################################
########################################################################################################################
########################################################################################################################
@follows( mkdir("tss") )
@files( os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_transcript_tss"] ), "tss/tss.transcript.composition" )
def annotateTranscriptTSSComposition( infile, outfile ):
    '''Establish the nucleotide composition of tss intervals'''
    to_cluster = True
    tss_extend = PARAMS["geneset_tss_extend"]
    statement = """zcat %(infile)s 
                   | slopBed -i stdin -g %(samtools_genome)s.fai -b %(tss_extend)s
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateTranscriptTSSComposition, suffix( ".composition"), ".composition.load" )
def loadTranscriptTSSComposition( infile, outfile ):
    '''Load the nucleotide composition of tss intervals'''
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=tss_transcript_comp
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@files( os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_tss"] ), "tss/tss.gene.composition" )
def annotateGeneTSSComposition( infile, outfile ):
    '''Establish the nucleotide composition of tss intervals'''
    to_cluster = True
    tss_extend = PARAMS["geneset_tss_extend"]
    statement = """zcat %(infile)s 
                   | slopBed -i stdin -g %(samtools_genome)s.fai -b %(tss_extend)s
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateGeneTSSComposition, suffix( ".composition"), ".composition.load" )
def loadGeneTSSComposition( infile, outfile ):
    '''Load the nucleotide composition of tss intervals'''
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=tss_gene_comp
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@files( os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_tss_interval"] ), "tss/tss.gene.interval.composition" )
def annotateGeneTSSIntervalComposition( infile, outfile ):
    '''Establish the nucleotide composition of tss intervals'''
    to_cluster = True
    statement = """zcat %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateGeneTSSIntervalComposition, suffix( ".composition"), ".composition.load" )
def loadGeneTSSIntervalComposition( infile, outfile ):
    '''Load the nucleotide composition of tss intervals'''
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=tss_gene_interval_comp
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@transform( loadTranscriptTSSComposition, suffix("tss.transcript.composition.load"), "tss.transcript.gc.export" )
def exportTranscriptTSSGCProfiles( infile, outfile ):
    '''Export file of GC content '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pGC FROM tss_transcript_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadGeneTSSComposition, suffix("tss.gene.composition.load"), "tss.gene.gc.export" )
def exportGeneTSSGCProfiles( infile, outfile ):
    '''Export file of GC content '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pGC FROM tss_gene_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadTranscriptTSSComposition, suffix("tss.transcript.composition.load"), "tss.transcript.cpg.export" )
def exportTranscriptTSSCpGObsExp( infile, outfile ):
    '''Export file of CpG observed / expected '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.CpG_ObsExp FROM tss_transcript_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadGeneTSSComposition, suffix("tss.gene.composition.load"), "tss.gene.cpg.export" )
def exportGeneTSSCpGObsExp( infile, outfile ):
    '''Export file of CpG observed / expected '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.CpG_ObsExp FROM tss_gene_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()
    
############################################################
@transform( loadTranscriptTSSComposition, suffix("tss.transcript.composition.load"), "tss.transcript.cpg_density.export" )
def exportTranscriptTSSCpGDensity( infile, outfile ):
    '''Export file of CpG density '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pCpG FROM tss_transcript_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( loadGeneTSSComposition, suffix("tss.gene.composition.load"), "tss.gene.cpg_density.export" )
def exportGeneTSSCpGDensity( infile, outfile ):
    '''Export file of CpG density '''
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    query = '''SELECT c.gene_id, c.pCpG FROM tss_gene_comp c;''' % locals()
    cc.execute( query )
    E.info( query )
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()
                               
########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 6: Identify and annotate long and short CAPseq intervals
########################################################################################################################
########################################################################################################################
########################################################################################################################
@follows( loadCapseqTranscriptTSSDistance, loadCapseqGenesetOverlap, mkdir("long_intervals") )
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"long_intervals/\1.long.genelist" )
def getLongIntervalGeneList( infile, outfile ):
    '''Generate bed file of top 500 longest intervals'''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".replicated.bed" ).replace("-","_").replace(".","_")
    geneset_name = PARAMS["geneset_name"]
    cc = dbhandle.cursor()
    statement = "ATTACH DATABASE '%s' AS annotations; "  % (PARAMS["geneset_database"])
    cc.execute(statement)
    # Extract data from db
    query = '''SELECT distinct t.gene_id
               FROM %(track)s_replicated_intervals i, %(track)s_replicated_%(geneset_name)s_transcript_tss_distance s, 
               %(track)s_replicated_%(geneset_name)s_overlap o, annotations.transcript_info t
               WHERE (substr(s.closest_id,1,18)=t.transcript_id
               or substr(s.closest_id,20,18)=t.transcript_id
               or substr(s.closest_id,39,18)=t.transcript_id
               or substr(s.closest_id,58,18)=t.transcript_id
               or substr(s.closest_id,77,18)=t.transcript_id)
               AND i.interval_id=s.gene_id
               AND o.gene_id=i.interval_id
               AND t.gene_biotype='protein_coding'
               AND i.length > 3000
               AND o.genes_pover2 > 0
               ORDER BY i.length desc
               LIMIT 500''' % locals()
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
            outs.write("%s%s" % (pre, str(r)) )
            pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()
    
############################################################
@follows( loadCapseqTranscriptTSSDistance, loadCapseqGenesetOverlap, mkdir("long_intervals") )
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"long_intervals/\1.short.genelist" )
def getShortIntervalGeneList( infile, outfile ):
    '''Generate bed file of 500 random intervals of normal size (<2kb)'''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    track = P.snip( os.path.basename( infile ), ".replicated.bed" ).replace("-","_").replace(".","_")
    geneset_name = PARAMS["geneset_name"]
    cc = dbhandle.cursor()
    statement = "ATTACH DATABASE '%s' AS annotations; "  % (PARAMS["geneset_database"])
    cc.execute(statement)
    # Extract data from db
    query = '''SELECT distinct t.gene_id
               FROM %(track)s_replicated_intervals i, %(track)s_replicated_%(geneset_name)s_transcript_tss_distance s, 
               %(track)s_replicated_%(geneset_name)s_overlap o, annotations.transcript_info t
               WHERE (substr(s.closest_id,1,18)=t.transcript_id
               or substr(s.closest_id,20,18)=t.transcript_id
               or substr(s.closest_id,39,18)=t.transcript_id
               or substr(s.closest_id,58,18)=t.transcript_id
               or substr(s.closest_id,77,18)=t.transcript_id)
               AND i.interval_id=s.gene_id
               AND o.gene_id=i.interval_id
               AND t.gene_biotype='protein_coding'
               AND i.length < 2000
               AND o.genes_pover2 > 0
               ORDER BY RANDOM()
               LIMIT 500''' % locals()
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
            outs.write("%s%s" % (pre, str(r)) )
            pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
@transform( (getLongIntervalGeneList, getShortIntervalGeneList), suffix(".genelist"), ".gtf.gz" )
def getLongIntervalGeneGTF( infile, outfile ):
    '''Filter  GTF file using list of  gene ids associated with long CAPseq intervals '''
    gene_file = os.path.join( PARAMS["geneset_dir"], PARAMS["geneset_gene_profile"])
    statement = '''zcat %(gene_file)s 
                   | python %(scriptsdir)s/gtf2gtf.py --filter=gene --apply=%(infile)s --log=%(outfile)s.log
                   | python %(scriptsdir)s/gtf2gtf.py --join-exons --log=%(outfile)s.log
                   | sed s/\\\\ttranscript\\\\t/\\\\texon\\\\t/g 
                   | gzip > %(outfile)s; '''
    P.run()

############################################################
############################################################
## CAPseq profile over long and short capseq interval genes
@follows(getLongIntervalGeneGTF)
@transform( "../merged_bams/*.merge.bam", regex(r"../merged_bams/(\S+).merge.bam"), r"long_intervals/\1.long_interval_genes.capseq_profile.log" )    
def longIntervalGeneCAPseqProfile(infile, outfile):
    '''plot CAPseq profiles over long intervals'''
    track = P.snip( os.path.basename(infile), ".merge.bam" )
    ofp = P.snip( outfile, ".log" )
    capseq = "long_intervals/"+track+".long.gtf.gz"
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                           --bamfile=%(infile)s 
                           --gtffile=%(capseq)s
                           --output-filename-pattern=%(ofp)s
                           --reporter=gene
                           --method=geneprofile
                           --log=%(outfile)s
                           --normalization=total-sum
                           --normalize-profile=area
                           --normalize-profile=counts
                           --normalize-profile=none'''
    P.run() 

############################################################
@follows(getLongIntervalGeneGTF)
@transform( "../merged_bams/*.merge.bam", regex(r"../merged_bams/(\S+).merge.bam"), r"long_intervals/\1.short_interval_genes.capseq_profile.log" )    
def shortIntervalGeneCAPseqProfile(infile, outfile):
    '''plot CAPseq profiles over long intervals'''
    track = P.snip( os.path.basename(infile), ".merge.bam" )
    ofp = P.snip( outfile, ".log" )
    capseq = "long_intervals/"+track+".short.gtf.gz"
    statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                           --bamfile=%(infile)s 
                           --gtffile=%(capseq)s
                           --output-filename-pattern=%(ofp)s
                           --reporter=gene
                           --method=geneprofile
                           --log=%(outfile)s
                           --normalization=total-sum
                           --normalize-profile=area
                           --normalize-profile=counts
                           --normalize-profile=none'''
    P.run() 
            
############################################################    
############################################################
## Analyse long and short CAPseq intervals
@transform( getLongIntervalGeneGTF, suffix(".gtf.gz"), ".chromatin_profile.log" )    
def longIntervalGeneChromatinProfile(infile, outfile):
    '''plot chromatin mark profiles over tissue-specific CAPseq intervals'''
    chromatin = P.asList(PARAMS["bigwig_chromatin"])
    track = P.snip( os.path.basename(infile), ".gtf.gz" )
    if len(chromatin[0]) > 0:
        for bw in chromatin:
            chromatin_track = P.snip( os.path.basename(bw), ".bam" )
            ofp = "long_intervals/" + track + ".genes." + chromatin_track + ".profile"    
            statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                           --bamfile=%(bw)s 
                           --gtffile=%(infile)s
                           --output-filename-pattern=%(ofp)s
                           --reporter=gene
                           --method=geneprofile
                           --log=%(outfile)s
                           --normalization=total-sum
                           --normalize-profile=area
                           --normalize-profile=counts
                           --normalize-profile=none'''
            P.run() 
    else:
        statement = '''touch %(outfile)s '''
        P.run()
        
############################################################
@transform( getLongIntervalGeneGTF, suffix(".gtf.gz"), ".chromatin_profile.log" )    
def shortIntervalGeneChromatinProfile(infile, outfile):
    '''plot chromatin mark profiles over genes with normal length CAPseq intervals'''
    chromatin = P.asList(PARAMS["bigwig_chromatin"])
    track = P.snip( os.path.basename(infile), ".gtf.gz" )
    if len(chromatin[0]) > 0:
        for bw in chromatin:
            chromatin_track = P.snip( os.path.basename(bw), ".bam" )
            ofp = "long_intervals/" + track + ".genes." + chromatin_track + ".profile"    
            statement = '''python %(scriptsdir)s/bam2geneprofile.py 
                           --bamfile=%(bw)s 
                           --gtffile=%(infile)s
                           --output-filename-pattern=%(ofp)s
                           --reporter=gene
                           --method=geneprofile
                           --log=%(outfile)s
                           --normalization=total-sum
                           --normalize-profile=area
                           --normalize-profile=counts
                           --normalize-profile=none'''
            P.run()
    else:
        statement = '''touch %(outfile)s '''
        P.run()

########################################################################################################################
########################################################################################################################
########################################################################################################################
## Section 7: Identify and annotate liver and testes tissue specific intervals
########################################################################################################################
########################################################################################################################
########################################################################################################################
@follows(copyCapseqReplicatedBedFiles, mkdir("liver_vs_testes") )
@files( ("*liver*.replicated.bed", "*testes*.replicated.bed"), "liver_vs_testes/liver.testes.venn" )
def liverTestesVenn(infiles, outfile):
    '''identify interval overlap between liver and testes. Merge intervals first.'''
    liver, testes = infiles
    liver_name = P.snip( os.path.basename(liver), ".bed" )
    testes_name = P.snip( os.path.basename(testes), ".bed" )
    to_cluster = True
    
    statement = '''cat %(liver)s %(testes)s | mergeBed -i stdin | awk 'OFS="\\t" {print $1,$2,$3,"CAPseq"NR}' > liver_vs_testes/liver.testes.merge.bed;
                   echo "Total merged intervals" > %(outfile)s; 
                   cat liver_vs_testes/liver.testes.merge.bed | wc -l >> %(outfile)s; 
                   echo "Liver & testes" >> %(outfile)s; 
                   intersectBed -a liver_vs_testes/liver.testes.merge.bed -b %(liver)s -u | intersectBed -a stdin -b %(testes)s -u > liver_vs_testes/liver.testes.shared.bed; 
                   cat liver_vs_testes/liver.testes.shared.bed | wc -l >> %(outfile)s; 
                   echo "Testes only" >> %(outfile)s; 
                   intersectBed -a liver_vs_testes/liver.testes.merge.bed -b %(liver)s -v > liver_vs_testes/%(testes_name)s.liver.testes.unique.bed; 
                   cat liver_vs_testes/%(testes_name)s.liver.testes.unique.bed | wc -l >> %(outfile)s; 
                   echo "Liver only" >> %(outfile)s; 
                   intersectBed -a liver_vs_testes/liver.testes.merge.bed -b %(testes)s -v > liver_vs_testes/%(liver_name)s.liver.testes.unique.bed; 
                   cat liver_vs_testes/%(liver_name)s.liver.testes.unique.bed | wc -l >> %(outfile)s;                   
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; '''
    P.run()
    
############################################################    
@transform( liverTestesVenn, suffix(".venn"), ".venn.load" )
def loadLiverTestesVenn(infile, outfile):
    '''Load liver testes venn overlap into database '''
    header = "category,intervals"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=liver_testes_venn
                      --header=%(header)s
                   > %(outfile)s '''
    P.run()
    
############################################################    
@follows(copyCapseqReplicatedBedFiles, exportCapseqIntergenicBed)
@files( ("*liver*.replicated.intergenic.bed", "*testes*.replicated.intergenic.bed"), "liver_vs_testes/liver.testes.intergenic.venn" )
def liverTestesIntergenicVenn(infiles, outfile):
    '''identify interval overlap between liver and testes for non-TSS associated intervals. Merge intervals first.'''
    liver, testes = infiles
    to_cluster = True
    statement = '''cat %(liver)s %(testes)s | mergeBed -i stdin > liver_vs_testes/liver.testes.intergenic.merge.bed;
                   echo "Total merged intervals" > %(outfile)s; cat liver_vs_testes/liver.testes.intergenic.merge.bed | wc -l >> %(outfile)s; 
                   echo "Liver & testes" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.intergenic.merge.bed -b %(liver)s -u | intersectBed -a stdin -b %(testes)s -u | wc -l >> %(outfile)s; 
                   echo "Testes only" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.intergenic.merge.bed -b %(liver)s -v | wc -l >> %(outfile)s; 
                   echo "Liver only" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.intergenic.merge.bed -b %(testes)s -v | wc -l >> %(outfile)s;                   
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; '''
    P.run()
    
############################################################    
@transform( liverTestesIntergenicVenn, suffix(".venn"), ".venn.load" )
def loadLiverTestesIntergenicVenn(infile, outfile):
    '''Load liver testes venn overlap into database '''
    header = "category,intervals"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=liver_testes_intergenic_venn
                      --header=%(header)s
                   > %(outfile)s '''
    P.run() 
    
############################################################   
@follows(liverTestesVenn) 
@files( "liver_vs_testes/liver.testes.shared.bed", "liver_vs_testes/liver.testes.shared.bed.load" )
def loadLiverTestesShared(infile, outfile):
    '''Load liver testes shared intervals into database '''
    header = "contig,start,end,interval_id"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=liver_testes_shared_intervals
                      --header=%(header)s
                   > %(outfile)s '''
    P.run()

############################################################       
@follows(liverTestesVenn) 
@transform( "liver_vs_testes/*.liver.testes.unique.bed", suffix(".liver.testes.unique.bed"),  ".liver.testes.unique.bed.load" )
def loadLiverTestesUnique(infile, outfile):
    '''Load liver testes unique intervals into database '''
    header = "contig,start,end,interval_id"
    track = P.snip(os.path.basename(infile), ".liver.testes.unique.bed")
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=%(track)s_liver_testes_unique_intervals
                      --header=%(header)s
                   > %(outfile)s '''
    P.run()

############################################################       
@follows(liverTestesVenn) 
@files( "liver_vs_testes/liver.testes.merge.bed", "liver_vs_testes/liver.testes.merge.bed.load" )
def loadLiverTestesMerge(infile, outfile):
    '''Load liver testes shared intervals into database '''
    header = "contig,start,end,interval_id"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=liver_testes_merged_intervals
                      --header=%(header)s
                   > %(outfile)s '''
    P.run()

############################################################
@follows(loadLiverTestesShared, loadLiverTestesUnique, loadLiverTestesMerge)
@merge( "liver_vs_testes/*.liver.testes.unique.bed", "liver_vs_testes/liver.testes.merge.sort.bed")
def exportLiverTestesMergeWithSort( infiles, outfile):
    '''Query database to produce a bed file which can be sorted by liver testes unique category and then length'''
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    tracks = []
    for infile in infiles:
        t = P.snip(os.path.basename(infile), ".liver.testes.unique.bed").replace("-","_").replace(".","_")
        tracks.append(t)
    # Extract data from db
    cc = dbhandle.cursor()
    query = '''SELECT m.contig, m.start, m.end, m.interval_id, 
               "sh_" || substr('000000' || (m.end-m.start), -6, 6)  as sort
               FROM liver_testes_merged_intervals m, liver_testes_shared_intervals s 
               WHERE m.interval_id=s.interval_id ''' % locals()
    for i, t in enumerate(tracks):
        query += '''UNION 
                    SELECT m.contig, m.start, m.end, m.interval_id, 
                    "a%(i)s_" || substr('000000' || (m.end-m.start), -6, 6)  as sort
                    FROM liver_testes_merged_intervals m, %(t)s_liver_testes_unique_intervals u%(i)s 
                    WHERE m.interval_id=u%(i)s.interval_id ''' % locals()
    print query
    cc.execute( query )
    # Write to file
    outs = open( outfile, "w")
    for result in cc:
        pre = ""
        for r in result:
            outs.write("%s%s" % (pre, str(r)) )
            pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
############################################################
## Analyse liver/testes tissue specific intervals
@follows( liverTestesVenn )
@files( "liver_vs_testes/liver.testes.merge.bed", "liver_vs_testes/liver.testes.merge.geneset_overlap" )
def annotateLiverTestesMergedGenesetOverlap( infile, outfile ):
    '''classify intervals according to their base pair overlap with respect to different genomic features (genes, TSS, upstream/downstream flanks) '''
    to_cluster = True
    feature_list = P.asList( PARAMS["geneset_feature_list"] )
    outfiles = ""
    first = True
    for feature in feature_list:
        feature_name = P.snip( os.path.basename( feature ), ".gtf" ).replace(".","_")
        outdir = os.path.dirname( outfile )
        outfiles += " %(outfile)s.%(feature_name)s " % locals()
        if first:
            cut_command = "cut -f1,4,5,6,8 "
            first = False
        else:
            cut_command = "cut -f4,5,6 "
        statement = """
                cat %(infile)s
                | python %(scriptsdir)s/bed2gff.py --as-gtf
                | python %(scriptsdir)s/gtf2table.py
		                --counter=overlap
		                --counter=length
		                --log=%(outfile)s.log
		                --filename-gff=%(geneset_dir)s/%(feature)s
		                --genome-file=%(genome_dir)s/%(genome)s
                | %(cut_command)s
                | sed s/nover/%(feature_name)s_nover/g
                | sed s/pover/%(feature_name)s_pover/g
                | sed s/min/length/
                > %(outfile)s.%(feature_name)s"""
        P.run()
    # Paste output together
    statement = '''paste  %(outfiles)s > %(outfile)s'''
    P.run()

############################################################
@transform( annotateLiverTestesMergedGenesetOverlap, suffix(".geneset_overlap"), ".geneset_overlap.load" )
def loadLiverTestesMergedGenesetOverlap( infile, outfile ):
    '''load interval annotations: genome architecture '''
    geneset_name = PARAMS["geneset_name"]
    track= P.snip( os.path.basename(infile), ".geneset_overlap").replace(".","_").replace("-","_")
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=liver_testes_merged_%(geneset_name)s_overlap
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@follows( liverTestesVenn )
@files( "liver_vs_testes/liver.testes.merge.bed", "liver_vs_testes/liver.testes.merge.transcript.tss.distance" )
def annotateLiverTestesMergedTranscriptTSSDistance( infile, outfile ):
    '''Compute distance from CAPseq intervals to nearest transcript TSS'''
    to_cluster = True
    annotation_file = os.path.join( PARAMS["geneset_dir"],PARAMS["geneset_transcript_tss"] )
    statement = """cat < %(infile)s 
                   | python %(scriptsdir)s/bed2gff.py --as-gtf 
	                 | python %(scriptsdir)s/gtf2table.py 
		                   --counter=distance-tss 
		                   --log=%(outfile)s.log 
                       --filename-gff=%(annotation_file)s 
                       --filename-format="bed" 
                   > %(outfile)s"""
    P.run()

############################################################
@transform( annotateLiverTestesMergedTranscriptTSSDistance, suffix( ".transcript.tss.distance"), ".transcript.tss.distance.load" )
def loadLiverTestesMergedTranscriptTSSDistance( infile, outfile ):
    '''Load CAPseq interval annotations: distance to transcript transcription start sites '''
    track= P.snip( os.path.basename(infile), ".transcript.tss.distance").replace(".","_").replace("-","_")
    geneset_name = PARAMS["geneset_name"]
    statement = """cat %(infile)s | python ~/src/csv2db.py 
                         --database=%(database)s
                         --table=liver_testes_merged_%(geneset_name)s_transcript_tss_distance
                         --index=gene_id
                         --index=closest_id
                         --index=id5
                         --index=id3
                 > %(outfile)s; """
    P.run()
    
############################################################    
@follows( liverTestesVenn )
@files( "liver_vs_testes/liver.testes.merge.bed", "liver_vs_testes/liver.testes.merge.composition" )
def annotateLiverTesteMergedComposition( infile, outfile ):
    '''Establish the nucleotide composition of tss intervals'''
    to_cluster = True
    statement = """cat %(infile)s | python %(scriptsdir)s/bed2gff.py --as-gtf 
                   | python %(scriptsdir)s/gtf2table.py 
                      	 --counter=composition-cpg
                      	 --log=%(outfile)s.log
                         --genome-file=%(genome_dir)s/%(genome)s
                   > %(outfile)s; """
    P.run()

############################################################
@transform( annotateLiverTesteMergedComposition, suffix( ".composition"), ".composition.load" )
def loadLiverTesteMergedComposition( infile, outfile ):
    '''Load the nucleotide composition of tss intervals'''
    statement = """cat %(infile)s | python ~/src/csv2db.py
                         --database=%(database)s
                         --table=liver_testes_merged_composition
                         --index=gene_id
                 > %(outfile)s; """
    P.run()

############################################################
@follows(copyCapseqReplicatedBedFiles, exportCapseqTSSBed)
@files( ("*liver*.replicated.transcript.tss.bed", "*testes*.replicated.transcript.tss.bed"), "liver_vs_testes/liver.testes.transcript.tss.venn" )
def liverTestesTSSVenn(infiles, outfile):
    '''identify interval overlap between liver and testes for TSS associated intervals. Merge intervals first.'''
    liver, testes = infiles
    to_cluster = True
    statement = '''cat %(liver)s %(testes)s | mergeBed -i stdin > liver_vs_testes/liver.testes.tss.merge.bed;
                   echo "Total merged intervals" > %(outfile)s; cat liver_vs_testes/liver.testes.tss.merge.bed | wc -l >> %(outfile)s; 
                   echo "Liver & testes" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.tss.merge.bed -b %(liver)s -u | intersectBed -a stdin -b %(testes)s -u | wc -l >> %(outfile)s; 
                   echo "Testes only" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.tss.merge.bed -b %(liver)s -v | wc -l >> %(outfile)s; 
                   echo "Liver only" >> %(outfile)s; intersectBed -a liver_vs_testes/liver.testes.tss.merge.bed -b %(testes)s -v | wc -l >> %(outfile)s;                   
                   sed -i '{N;s/\\n/\\t/g}' %(outfile)s; '''
    P.run()
    
############################################################    
@transform( liverTestesTSSVenn, suffix(".venn"), ".venn.load" )
def loadLiverTestesTSSVenn(infile, outfile):
    '''Load liver testes venn overlap into database '''
    header = "category,intervals"
    statement = '''cat %(infile)s | python %(scriptsdir)s/csv2db.py
                      --database=%(database)s
                      --table=liver_testes_tss_venn
                      --header=%(header)s
                   > %(outfile)s '''
    P.run() 

############################################################    
@follows( exportLiverTestesMergeWithSort )
@transform( copyCapseqReplicatedBedFiles, regex(r"(\S+).replicated.bed"), r"liver_vs_testes/\1.replicated.liver.testes.merge.peakshape.gz" )
def getPeakShapeLiverTestes(infile, outfile):
    '''Cluster intervals based on peak shape '''
    track = P.snip( os.path.basename( infile ), ".replicated.bed" )
    expt_track = track + "-agg"
    replicates = EXPERIMENTS[expt_track]
    #ofp = "replicated_intervals/" + track + ".liver.testes.merge.peakshape"
    bedfile = "liver_vs_testes/liver.testes.merge.sort.bed"
    samfiles, offsets = [], []
    for t in replicates:
        fn = "../bam/%s.norm.bam" % t.asFile()
        assert os.path.exists( fn ), "could not find bamfile %s for track %s" % ( fn, str(t))
        samfiles.append( fn )
        fn = "../macs/with_input/%s.macs" % t.asFile()
        if os.path.exists( fn ):
            offsets.append( PIntervals.getPeakShiftFromMacs( fn ) )

    bamfiles = " ".join( ("--bamfile=%s" % x) for x in samfiles )
    shifts =  " ".join( ("--shift=%s" % y)  for y in offsets )
    statement = '''python %(scriptsdir)s/bam2peakshape.py 
                       %(bamfiles)s 
                       --bedfile=%(bedfile)s
                       --output-filename-pattern=%(outfile)s.%%s
                       %(shifts)s
                       --sort=peak-width
                       --sort=peak-height
                       --sort=interval-width
                       --sort=interval-score
                       --window-size=3000
                       --bin-size=10
                       --normalization=sum
                       --force
                       --log=%(outfile)s.log
                   | gzip
                   > %(outfile)s '''
    P.run()

############################################################
@follows( liverTestesVenn )
@files( "liver_vs_testes/*.liver.testes.unique.bed", "liver_vs_testes/liver.testes.chromatin.log" )    
def liverTestesUniqueChromatinProfile(infiles, outfile):
    '''plot chromatin mark profiles over tissue-specific CAPseq intervals'''
    chromatin = P.asList(PARAMS["bigwig_chromatin"])
    if len(chromatin[0]) > 0:
        for infile in infiles:
            track = P.snip( os.path.basename(infile), ".liver.testes.unique.bed" )
            outtemp = P.getTempFile()
            tmpfilename = outtemp.name
            for bw in chromatin:
                # still need to normalise
                chromatin_track = P.snip( os.path.basename(bw), ".bw" )
                ofp = "liver_vs_testes/" + track + "." + chromatin_track + ".profile"    
                statement = '''cat %(infile)s | python %(scriptsdir)s/bed2gff.py --as-gtf | gzip > %(tmpfilename)s.gtf.gz;
                               python %(scriptsdir)s/bam2geneprofile.py 
                               --bamfile=%(bw)s 
                               --gtffile=%(tmpfilename)s.gtf.gz
                               --output-filename-pattern=%(ofp)s
                               --reporter=interval
                               --method=intervalprofile
                               --log=%(outfile)s'''
                P.run() 
    else:
        statement = '''touch %(outfile)s '''
        P.run()
                     
############################################################
############################################################
## Export gene lists
@follows(loadCapseqTranscriptTSSDistance)
@transform( loadLiverTestesUnique, suffix(".liver.testes.unique.bed.load"), ".liver.testes.unique.genes.export" )
def exportLiverTestesSpecificCAPseqGenes( infile, outfile ):
    '''Export liver vs testes tissue specific CAPseq genes '''
    track = P.snip( os.path.basename( infile ), ".liver.testes.unique.bed.load" ).replace("-","_").replace(".","_")
    geneset_name = PARAMS["geneset_name"]
    # Connect to DB
    dbhandle = sqlite3.connect( PARAMS["database"] )
    cc = dbhandle.cursor()
    statement = "ATTACH DATABASE '%s' AS annotations; "  % (PARAMS["geneset_database"])
    cc.execute(statement)
    # Extract data from db
    query = '''SELECT distinct a.gene_id
               FROM %(track)s_liver_testes_unique_intervals u, 
               %(track)s_%(geneset_name)s_transcript_tss_distance t, annotations.transcript_info a
               WHERE u.interval_id=t.gene_id
               AND t.closest_dist < 1000
               AND t.closest_id=a.transcript_id
               AND a.gene_biotype='protein_coding';''' % locals()
    cc.execute( query )
    E.info( query )
    # Write to file
    outs = open( outfile, "w")
    outs.write("gene_id\n")
    for result in cc:
        pre = ""
        for r in result:
          outs.write("%s%s" % (pre, str(r)) )
          pre = "\t"
        outs.write("\n")
    cc.close()
    outs.close()

############################################################
############################################################
## GO analysis    
@transform( exportLiverTestesSpecificCAPseqGenes, suffix(".liver.testes.unique.genes.export"), ".liver.testes.unique.genes.go" )
def runGOOnGeneLists( infile, outfile ):
    PipelineGO.runGOFromFiles( outfile = outfile,
                               outdir = "go",
                               fg_file = infile,
                               bg_file = None,
                               go_file = os.path.join(PARAMS["geneset_dir"], PARAMS_ANNOTATIONS["interface_go"] ),
                               ontology_file = os.path.join(PARAMS["geneset_dir"], PARAMS_ANNOTATIONS["interface_go_obo"] ),
                               minimum_counts = PARAMS["go_minimum_counts"] )

############################################################
@transform( exportLiverTestesSpecificCAPseqGenes, suffix(".liver.testes.unique.genes.export"), ".liver.testes.unique.genes.goslim" )
def runGOSlimOnGeneLists( infile, outfile ):
    PipelineGO.runGOFromFiles( outfile = outfile,
                               outdir = "go",
                               fg_file = infile,
                               bg_file = None,
                               go_file = os.path.join(PARAMS["geneset_dir"], PARAMS_ANNOTATIONS["interface_goslim"] ),
                               ontology_file = os.path.join(PARAMS["geneset_dir"], PARAMS_ANNOTATIONS["interface_goslim_obo"]),
                               minimum_counts = PARAMS["go_minimum_counts"] )

############################################################
@transform( (runGOOnGeneLists, runGOSlimOnGeneLists), regex( "(.*)"), r"\1.load" )
def loadGOResults( infile, outfile ):
    '''load GO results.'''
    P.load( os.path.join( "go", "all.biol_process.fold"), outfile )
    
############################################################
############################################################
############################################################
## REPORTS
@follows( mkdir( "report" ) )
def build_report():
    '''build report from scratch.'''

    E.info( "starting documentation build process from scratch" )
    P.run_report( clean = True )

############################################################
@follows( mkdir( "report" ) )
def update_report():
    '''update report.'''

    E.info( "updating documentation" )
    P.run_report( clean = False )

############################################################
@files( "report.log", "publish.log")
def publish_report(infile, outfile):
    '''Link bed, bam, wig and report files to web '''
    publish_dir = PARAMS["publish_dir"]
    species = PARAMS["genome"]
    report_dir = os.path.join(publish_dir, species)
    bam_dir = os.path.join(publish_dir, "bam")
    bed_dir = os.path.join(publish_dir, "bed")
    wig_dir = os.path.join(publish_dir, "wig")  
    tss_dir = os.path.join(publish_dir, "tss")
    tss_dist_dir = os.path.join(publish_dir, "tss_distance")
    gc_dir = os.path.join(publish_dir, "gc")
    cgi_dir = os.path.join(publish_dir, "cpg")
    cpg_density_dir = os.path.join(publish_dir, "cpg_density")
    length_dir = os.path.join(publish_dir, "length")
    long_interval_dir = os.path.join(publish_dir, "long_intervals")
    working_dir = os.getcwd()
    capseq_dir = PARAMS["capseq_dir"]
    # create directories if they do not exist
    statement = '''[ -d %(report_dir)s ] || mkdir %(report_dir)s; 
                   [ -d %(bam_dir)s ] || mkdir %(bam_dir)s;
                   [ -d %(bed_dir)s ] || mkdir %(bed_dir)s;
                   [ -d %(bed_dir)s/no_input ] || mkdir %(bed_dir)s/no_input;
                   [ -d %(bed_dir)s/replicates ] || mkdir %(bed_dir)s/replicates;
                   [ -d %(bed_dir)s/tissue_specific ] || mkdir %(bed_dir)s/tissue_specific;
                   [ -d %(bed_dir)s/liver_vs_testes ] || mkdir %(bed_dir)s/liver_vs_testes;
                   [ -d %(wig_dir)s ] || mkdir %(wig_dir)s;
                   [ -d %(tss_dir)s ] || mkdir %(tss_dir)s;
                   [ -d %(tss_dist_dir)s ] || mkdir %(tss_dist_dir)s;
                   [ -d %(gc_dir)s ] || mkdir %(gc_dir)s;
                   [ -d %(cgi_dir)s ] || mkdir %(cgi_dir)s;
                   [ -d %(cpg_density_dir)s ] || mkdir %(cpg_density_dir)s;
                   [ -d %(length_dir)s ] || mkdir %(length_dir)s;
                   [ -d %(long_interval_dir)s ] || mkdir %(long_interval_dir)s;'''
    statement += '''cp -rf report/html/* %(report_dir)s > %(outfile)s; '''
    statement += '''cp -sn %(capseq_dir)s/bam/*.norm.bam %(bam_dir)s >> %(outfile)s;'''
    statement += '''cp -sn %(capseq_dir)s/macs/with_input/*/*/*.wig.gz %(wig_dir)s >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/*.replicated.bed %(bed_dir)s >> %(outfile)s;'''    
    statement += '''cp -sn %(capseq_dir)s/intervals/*solo*.bed %(bed_dir)s/no_input >> %(outfile)s; ''' 
    statement += '''cp -sn %(capseq_dir)s/intervals/*.merged.cleaned.bed %(bed_dir)s/replicates >> %(outfile)s; '''
    statement += '''cp -sn %(capseq_dir)s/replicated_intervals/*.replicated.unique.bed %(bed_dir)s/tissue_specific >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/tss-profile/*.tss-profile*.counts.tsv.gz %(tss_dir)s >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/*.replicated.gc.export %(gc_dir)s >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/tss/tss.gene.gc.export %(gc_dir)s/%(species)s.tss.gene.gc.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/tss/tss.transcript.gc.export %(gc_dir)s/%(species)s.tss.transcript.gc.export >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/cgi/cgi.gc.export %(gc_dir)s/%(species)s.cgi.gc.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/*.replicated.cpg.export %(cgi_dir)s >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/tss/tss.gene.cpg.export %(cgi_dir)s/%(species)s.tss.gene.cpg.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/tss/tss.transcript.cpg.export %(cgi_dir)s/%(species)s.tss.transcript.cpg.export >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/cgi/cgi.cpg.export %(cgi_dir)s/%(species)s.cgi.cpg.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/*.replicated.cpg_density.export %(cpg_density_dir)s >> %(outfile)s; '''   
    statement += '''cp -sn %(working_dir)s/tss/tss.gene.cpg_density.export %(cpg_density_dir)s/%(species)s.tss.gene.cpg_density.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/tss/tss.transcript.cpg_density.export %(cpg_density_dir)s/%(species)s.tss.transcript.cpg_density.export >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/cgi/cgi.cpg_density.export %(cpg_density_dir)s/%(species)s.cgi.cpg_density.export >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/*.length %(length_dir)s >> %(outfile)s; ''' 
    statement += '''cp -sn %(working_dir)s/*.gene.tss.distance %(tss_dist_dir)s >> %(outfile)s; '''     
    statement += '''cp -sn %(working_dir)s/long_intervals/*.capseq_profile.counts.tsv.gz %(long_interval_dir)s >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/long_intervals/*.profile.counts.tsv.gz %(long_interval_dir)s >> %(outfile)s; '''
    statement += '''cp -sn %(working_dir)s/liver_vs_testes/*.liver.testes.unique.bed %(bed_dir)s/liver_vs_testes >> %(outfile)s; ''' 
 
    P.run()

############################################################
############################################################
############################################################
## Pipeline organisation

@follows(annotateCapseqGenesetOverlap,
         loadCapseqGenesetOverlap,
         getCapseqGeneTSSOverlapCount,
         loadCapseqGeneTSSOverlapCount,
         annotateCapseqTranscriptTSSDistance,
         loadCapseqTranscriptTSSDistance,
         annotateCapseqGeneTSSDistance,
         loadCapseqGeneTSSDistance,
         exportCapseqTSSBed,
         exportCapseqIntergenicBed,
         getCapseqNoncodingTSSDistance,
         loadCapseqNoncodingTSSDistance,
         exportCapseqTSSDistanceGeneList,
         runGenomicFeaturesGAT,
         loadGenomicFeaturesGAT )
def capseqGeneset():
    '''Annoatate CAPseq intervals using a geneset specified in the ini file'''
    pass

@follows(getReplicatedTranscriptTSSProfile,
         getReplicatedTranscriptTSSProfileCapseq,
         getReplicatedTranscriptTSSProfileNoCapseq,
         getReplicatedGeneTSSProfile,
         getReplicatedGeneTSSProfileCapseq,
         getReplicatedGeneTSSProfileNoCapseq,
         getReplicatedTranscriptProfile,
         getReplicatedGeneProfile)
def capseqProfiles():
    '''Calculate CAPseq profile over genes and TSSs using a geneset specified in the ini file'''
    pass      
       
# Section 2
@follows( annotateCapseqComposition,
         loadCapseqComposition,
         annotateControlComposition,
         loadControlComposition,
         annotateFlankingCompositionLeft,
         loadFlankingCompositionLeft,
         annotateFlankingCompositionRight,
         loadFlankingCompositionRight,
         exportCapseqGCProfiles,
         exportCapseqCpGObsExp,
         exportCapseqCpGDensity )
def capseqComposition():
    '''Annotate nucleotide composition of CAPseq intervals and export to text files for plotting'''
    pass

# Section 3
@follows( getCapseqCGIOverlapCount,
         loadCapseqCGIOverlapCount,
         getCGIAndCapseqIntervals,
         loadCGIAndCapseqIntervals,
         getCapseqSpecificIntervals,
         loadCapseqSpecificIntervals,
         getPredictedCGIIntervals,
         loadPredictedCGIIntervals,
         getExternalBedStats,
         loadExternalBedStats,
         getChromatinMarkOverlap,
         loadChromatinMarkIntervals,
         getChipseqOverlap,
         loadChipseqIntervals,
         getCapseqOverlap,
         loadCapseqIntervals,
         buildGATWorkspace,
         runExternalDatasetGAT,
         loadExternalDatasetGAT )
def compareExternal():
    '''Compare intervals external bed files'''
    pass

# Section 4
@follows( loadUCSCPredictedCGIIntervals,
         annotateCGIComposition,
         loadCGIComposition,
         getCGITranscriptTSSOverlapCount,
         loadCGITranscriptTSSOverlapCount,
         getCGIGeneTSSOverlapCount,
         loadCGIGeneTSSOverlapCount,
         annotateCGIGenesetOverlap,
         loadCGIGenesetOverlap,
         exportCGICpGDensity,
         exportCGICpGObsExp,
         exportCGIGCProfiles )
def predictedCGIs():
    '''Annotate predicted CGI intervals'''
    pass

# Section 5
@follows( annotateTranscriptTSSComposition,
         loadTranscriptTSSComposition,
         annotateGeneTSSComposition,
         loadGeneTSSComposition,
         annotateGeneTSSIntervalComposition,
         loadGeneTSSIntervalComposition,
         exportTranscriptTSSCpGDensity,
         exportGeneTSSCpGDensity,
         exportTranscriptTSSCpGObsExp,
         exportGeneTSSCpGObsExp,
         exportTranscriptTSSGCProfiles,
         exportGeneTSSGCProfiles )
def genesetTSSComposition():
    '''Annotate the nucleotide composition of the TSS of the supplied gene set'''
    pass

# Section 6
@follows( getLongIntervalGeneList,
         getShortIntervalGeneList,
         getLongIntervalGeneGTF,
         longIntervalGeneCAPseqProfile,
         shortIntervalGeneCAPseqProfile,
         longIntervalGeneChromatinProfile, 
         shortIntervalGeneChromatinProfile )
def longIntervals():
    '''Annotate long vs short CAPseq intervals'''
    pass

# Section 7
@follows( liverTestesVenn,
         loadLiverTestesVenn,
         liverTestesIntergenicVenn,
         loadLiverTestesIntergenicVenn,
         loadLiverTestesShared,
         loadLiverTestesUnique,
         loadLiverTestesMerge,
         exportLiverTestesMergeWithSort,
         annotateLiverTestesMergedGenesetOverlap,
         loadLiverTestesMergedGenesetOverlap,
         annotateLiverTestesMergedTranscriptTSSDistance,
         loadLiverTestesMergedTranscriptTSSDistance,
         annotateLiverTesteMergedComposition,
         loadLiverTesteMergedComposition,
         liverTestesTSSVenn,
         loadLiverTestesTSSVenn,
         getPeakShapeLiverTestes,
         liverTestesUniqueChromatinProfile,
         exportLiverTestesSpecificCAPseqGenes )
def liverTestes():
    '''Annotate liver vs testes specific CAPseq intervals'''
    pass

@follows( build_report, publish_report )
def fullReport():
    '''Build and publish report'''
    pass

@follows( capseqGeneset,
          capseqComposition,
          compareExternal,
          predictedCGIs,
          genesetTSSComposition,
          longIntervals,
          liverTestes)
def full():
    '''Run the full pipeline.'''
    pass

if __name__== "__main__":
    sys.exit( P.main(sys.argv) )
    
